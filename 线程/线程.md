# 线程/进程

- 进程是系统分配资源的基本单位。
- 线程是系统调度的基本单位。

# 线程池/锁

## 线程池

### corePoolSize

线程池核心线程数量，核心线程不会被回收，即使没有任务执行，也会保持空闲状态。

### maximumPoolSize

池允许最大的线程数，当线程数量达到corePoolSize，且workQueue队列塞满任务了之后，继续创建线程。

### keepAliveTime

超过corePoolSize之后的“临时线程”的存活时间。

### unit

keepAliveTime的单位。

### workQueue

当前线程数超过corePoolSize时，新的任务会处在等待状态，并存在workQueue中，BlockingQueue是一个先进先出的阻塞式队列实现，底层实现会涉及Java并发的AQS机制。

①ArrayBlockingQueue

基于数组的有界阻塞队列，按FIFO排序。新任务进来后，会放到该队列的队尾，有界的数组可以防止资源耗尽问题。当线程池中线程数量达到corePoolSize后，再有新任务进来，则会将任务放入该队列的队尾，等待被调度。如果队列已经是满的，则创建一个新线程，如果线程数量已经达到maxPoolSize，则会执行拒绝策略。

②LinkedBlockingQuene

基于链表的无界阻塞队列（其实最大容量为Interger.MAX），按照FIFO排序。由于该队列的近似无界性，当线程池中线程数量达到corePoolSize后，再有新任务进来，会一直存入该队列，而不会去创建新线程直到maxPoolSize，因此使用该工作队列时，参数maxPoolSize其实是不起作用的。

③SynchronousQuene

一个不缓存任务的阻塞队列，生产者放入一个任务必须等到消费者取出这个任务。也就是说新任务进来时，不会缓存，而是直接被调度执行该任务，如果没有可用线程，则创建新线程，如果线程数量达到maxPoolSize，则执行拒绝策略。

④PriorityBlockingQueue

具有优先级的无界阻塞队列，优先级通过参数Comparator实现。

### threadFactory

创建线程的工厂类，通常我们会自定义一个threadFactory设置线程的名称，这样我们就可以知道线程是由哪个工厂类创建的，可以快速定位。

### handler

线程池执行拒绝策略，当线数量达到maximumPoolSize大小，并且workQueue也已经塞满了任务的情况下，线程池会调用handler拒绝策略来处理请求。

系统默认的拒绝策略有以下几种：

AbortPolicy：为线程池默认的拒绝策略，该策略直接抛异常处理。

DiscardPolicy：直接抛弃不处理。

DiscardOldestPolicy：丢弃队列中最老的任务。

CallerRunsPolicy：将任务分配给当前执行execute方法线程来处理。

我们还可以自定义拒绝策略，只需要实现RejectedExecutionHandler接口即可，友好的拒绝策略实现有如下：

将数据保存到数据，待系统空闲时再进行处理。

将数据用日志进行记录，后由人工处理。

## 锁-AQS

### ReentrantLock

head放在队列中有什么用处？为什么不是一个等待锁的线程作为head呢？原因很简单，因为每个等待线程都有可能被中断而取消，对于一个已经取消的线程，自然是有机会就把它gc了。那么gc前一定得让后续的Node成为head，**这样一来setHead的操作过于分散**，而且要应对多种线程状态的变化来设置head，这样就太麻烦了。所以这里很巧妙地将head的next设置为等待锁的Node，head就相当于一个引导的作用，因为head没有线程，所以不存在“取消”这种状态。

![锁AQS](pic\锁AQS.png)

#### FairSync

[tryAcquire](#tryAcquire)

[addWaiter](#addWaiter)

[acquireQueued](#acquireQueued)

```java
//公平锁，lock方法
acquire(1);

//acquire方法
if (!tryAcquire(arg) &&
            acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
            selfInterrupt();


```

##### tryAcquire

在公平锁的acquire方法中，tryAcquire()方法为试图获取锁，true为成功获取到了锁，false为未获取到锁

[hasQueuedPredecessors](#hasQueuedPredecessors)

```java
protected final boolean tryAcquire(int acquires) {

    //tryAcquire方法
    final Thread current = Thread.currentThread();
    int c = getState();//获得状态，0未加锁，1加锁
    if (c == 0) {
        if (!hasQueuedPredecessors() &&
            compareAndSetState(0, acquires)) {
            setExclusiveOwnerThread(current);
            return true;
        }
    }
    //可重入锁
    else if (current == getExclusiveOwnerThread()) {
        int nextc = c + acquires;
        if (nextc < 0)
            throw new Error("Maximum lock count exceeded");
        setState(nextc);
        return true;
    }
    return false;
}
```

[返回上一级FairSync](#FairSync)

##### hasQueuedPredecessors

返回值为true，不可以获取锁需要排队，返回值为false，可以尝试获取锁。

```java
Node t = tail; // Read fields in reverse initialization order
Node h = head;
Node s;
//如果h==t：
//	1.队列为空，可以尝试加锁。
//	2.队列不为空，但队列只有一个节点。
//如果h!=t，队列不止一个节点。
//(s=h.next)==null:
//	这种情况是为了排除有多个节点的情况，如果头节点的next为null，则只有一个节点。
//s.thread != Thread.currentThread()
//	s为队列头的下一个节点，代表第一个等待的线程节点，如果当前线程与之相等，此字段为false,则代表可以尝试入队。
return h != t &&   
    ((s = h.next) == null || s.thread != Thread.currentThread());
```

[返回上一级tryAcquire](#tryAcquire)

##### addWaiter

[enq](#enq)

```java
private Node addWaiter(Node mode) {
    //mode=null
    Node node = new Node(Thread.currentThread(), mode);
    // Try the fast path of enq; backup to full enq on failure
    Node pred = tail;
    //如果尾节点为空，队列为空，逻辑在end方法中。
    if (pred != null) {
        node.prev = pred;
        //如果不为空，将此节点设置为尾节点，并连接在队列上。
        if (compareAndSetTail(pred, node)) {
            pred.next = node;
            return node;
        }
    }
    enq(node);
    return node;
}
```

[返回上一级FairSync](#FairSync)

##### enq

```java
private Node enq(final Node node) {
    for (;;) {
        Node t = tail;
        if (t == null) { // Must initialize
            //接上，如果队列为空，设置一个空的头节点，并将头，尾指向这个节点。
            if (compareAndSetHead(new Node()))
                tail = head;
        } else {
            //循环直到连接成功
            node.prev = t;
            if (compareAndSetTail(t, node)) {
                t.next = node;
                return t;
            }
        }
    }
}
```

[返回上一级addWaiter](#addWaiter)

##### acquireQueued

[shouldParkAfterFailedAcquire](#shouldParkAfterFailedAcquire)

返回值尾false，代表队列头直接加锁成功，返回true，代表被唤醒并执行成功。

```java
final boolean acquireQueued(final Node node, int arg) {
    boolean failed = true;
    try {
        boolean interrupted = false;
        for (;;) {
            //获得当前线程节点的前一个节点
            final Node p = node.predecessor();
            //如果前一个节点是头，尝试加锁
            if (p == head && tryAcquire(arg)) {
                //如果加锁成功，断前边的头，并把当前节点设置为头节点。
                setHead(node);
                p.next = null; // help GC
                failed = false;
                return interrupted;
            }
            if (shouldParkAfterFailedAcquire(p, node) &&
                parkAndCheckInterrupt())
                interrupted = true;
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
```

[返回上一级FairSync](#FairSync)

##### shouldParkAfterFailedAcquire

aqs队列里边-1为挂起状态，每增加一个尾节点，都将前一个节点设置-1并挂起。

```java
private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {
    int ws = pred.waitStatus;
    if (ws == Node.SIGNAL)
        //ws==-1,前节点为-1，可以挂起
        /*
         * This node has already set status asking a release
         * to signal it, so it can safely park.
         */
        return true;
    if (ws > 0) {
        /*
         * Predecessor was cancelled. Skip over predecessors and
         * indicate retry.
         */
        //说明前边取消等待了，找到不取消的点。连接当前节点与最前边的点。
        do {
            node.prev = pred = pred.prev;
        } while (pred.waitStatus > 0);
        pred.next = node;
    } else {
        /*
         * waitStatus must be 0 or PROPAGATE.  Indicate that we
         * need a signal, but don't park yet.  Caller will need to
         * retry to make sure it cannot acquire before parking.
         */
        //将前一个节点的ws设置为-1，自己不能设置自己的状态
        compareAndSetWaitStatus(pred, ws, Node.SIGNAL);
    }
    return false;
}

///////////////////////
private final boolean parkAndCheckInterrupt() {
    //挂起当前线程
    LockSupport.park(this);
    return Thread.interrupted();
}
```

[返回上一级acquireQueued](#acquireQueued)

#### unlock

ReentrantLock的unlock方法只有一个，是相同的。

```java
public void unlock() {
    sync.release(1);
}
```

```java
public final boolean release(int arg) {
    //尝试解锁
    if (tryRelease(arg)) {
        Node h = head;
        if (h != null && h.waitStatus != 0)
            unparkSuccessor(h);
        return true;
    }
    //false代表锁仍被持有，比如可重入锁。
    return false;
}

/****************************************/
    
protected final boolean tryRelease(int releases) {
    int c = getState() - releases;
    if (Thread.currentThread() != getExclusiveOwnerThread())
        throw new IllegalMonitorStateException();
    boolean free = false;
    if (c == 0) {
        //释放锁成功返回true，设置当前占用为null
        free = true;
        setExclusiveOwnerThread(null);
    }
    //如果c！=0，return false。
    setState(c);
    return free;
}
/******************************************/
//将头节点的ws设置为0;代表被唤醒，
private void unparkSuccessor(Node node) {
        /*
         * If status is negative (i.e., possibly needing signal) try
         * to clear in anticipation of signalling.  It is OK if this
         * fails or if status is changed by waiting thread.
         */
        int ws = node.waitStatus;
        if (ws < 0)
            compareAndSetWaitStatus(node, ws, 0);

        /*
         * Thread to unpark is held in successor, which is normally
         * just the next node.  But if cancelled or apparently null,
         * traverse backwards from tail to find the actual
         * non-cancelled successor.
         */
        Node s = node.next;
        if (s == null || s.waitStatus > 0) {
            s = null;
            
        //新节点pre指向tail，tail指向新节点，这里后继指向前驱的指针是由CAS操作保证线程安全的。而cas操作之后t.next=node之前，可能会有其他线程进来。所以出现了问题，从尾部向前遍历是一定能遍历到所有的节点。详看end中：
            /**
            else {
                //看这里
                node.prev = t;
                if (compareAndSetTail(t, node)) {
                    t.next = node;
                    return t;
                }
            **/
            for (Node t = tail; t != null && t != node; t = t.prev)
                if (t.waitStatus <= 0)
                    s = t;
        }
        if (s != null)
            LockSupport.unpark(s.thread);
    }

```

> An AbstractQueuedSynchronizer queue node contains a next link to its successor. But because there are no applicable techniques for lock-free atomic insertion of double-linked list nodes using compareAndSet, **this link is not atomically set as part of insertion**; it is simply assigned: pred.next = node; after the insertion. This is reflected in all usages. **The next link is treated only as an optimized path**. If a node's successor does not appear to exist (or appears to be cancelled) via its next field, it is always possible to start at the tail of the list and traverse backwards using the pred field to accurately check if there really is one.

# 锁升级

- CAS底层使用lock指令（cpu）：

  - 确保对内存的读-改-写操作原子执行。在Pentium及Pentium之前的处理器中，带有lock前缀的指令在执行期间会锁住总线，使得其他处理器暂时无法通过总线访问内存。很显然，这会带来昂贵的开销。从Pentium 4，Intel Xeon及P6处理器开始，intel在原有总线锁的基础上做了一个很有意义的优化：如果要访问的内存区域（area of memory）在lock前缀指令执行期间已经在处理器内部的缓存中被锁定（即包含该内存区域的缓存行当前处于独占或已修改状态），并且该内存区域被完全包含在单个缓存行（cache line）中，那么处理器将直接执行该指令。由于在指令执行期间该缓存行会一直被锁定，其它处理器无法读/写该指令要访问的内存区域，因此能保证指令执行的原子性。这个操作过程叫做缓存锁定（cache locking），缓存锁定将大大降低lock前缀指令的执行开销，但是当多处理器之间的竞争程度很高或者指令访问的内存地址未对齐时，仍然会锁住总线。
    - 处理器自动保证基本内存操作的原子性：首先处理器会自动保证基本的内存操作的原子性。处理器保证从系统内存当中读取或者写入一个字节是原子的，意思是当一个处理器读取一个字节时，其他处理器不能访问这个字节的内存地址。奔腾6和最新的处理器能自动保证单处理器对同一个缓存行里进行16/32/64位的操作是原子的，但是复杂的内存操作处理器不能自动保证其原子性，比如跨总线宽度，跨多个缓存行，跨页表的访问。但是处理器提供总线锁定和缓存锁定两个机制来保证复杂内存操作的原子性。 
    - 使用总线锁保证原子性：第一个机制是通过总线锁保证原子性。如果多个处理器同时对共享变量进行读改写（i++就是经典的读改写操作）操作，那么共享变量就会被多个处理器同时进行操作，这样读改写操作就不是原子的，操作完之后共享变量的值会和期望的不一致，举个例子：如果i=1,我们进行两次i++操作，我们期望的结果是3，但是有可能结果是2。原因是有可能多个处理器同时从各自的缓存中读取变量i，分别进行加一操作，然后分别写入系统内存当中。那么想要保证读改写共享变量的操作是原子的，就必须保证CPU1读改写共享变量的时候，CPU2不能操作缓存了该共享变量内存地址的缓存。处理器使用总线锁就是来解决这个问题的。所谓总线锁就是使用处理器提供的一个LOCK＃信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住,那么该处理器可以独占使用共享内存。
    - 使用缓存锁保证原子性：第二个机制是通过缓存锁定保证原子性。在同一时刻我们只需保证对某个内存地址的操作是原子性即可，但总线锁定把CPU和内存之间通信锁住了，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，最近的处理器在某些场合下使用缓存锁定代替总线锁定来进行优化。频繁使用的内存会缓存在处理器的L1，L2和L3高速缓存里，那么原子操作就可以直接在处理器内部缓存中进行，并不需要声明总线锁，在奔腾6和最近的处理器中可以使用“缓存锁定”的方式来实现复杂的原子性。所谓“缓存锁定”就是如果缓存在处理器缓存行中内存区域在LOCK操作期间被锁定，当它执行锁操作回写内存时，处理器不在总线上声言LOCK＃信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性，因为缓存一致性机制会阻止同时修改被两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时会起缓存行无效，在例1中，当CPU1修改缓存行中的i时使用缓存锁定，那么CPU2就不能同时缓存了i的缓存行。但是有两种情况下处理器不会使用缓存锁定。第一种情况是：当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行（cache line），则处理器会调用总线锁定。第二种情况是：有些处理器不支持缓存锁定。对于Inter486和奔腾处理器,就算锁定的内存区域在处理器的缓存行中也会调用总线锁定。
  - 禁止该指令与之前和之后的读和写指令重排序。
- 把写缓冲区中的所有数据刷新到内存中。
  - 总线锁、缓存锁、MESI：https://blog.csdn.net/qq_35642036/article/details/82801708
  
- 偏向锁：相当于贴个标签，没有锁竞争情况下效率高。
- 偏向锁默认打开，刚开始创建对象不是偏向锁，4s后创建空对象是偏向锁

